{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "    <img src=\"https://github.com/jessepisel/energy_analytics/blob/master/EA_logo.jpg?raw=true\" width=\"220\" height=\"240\" />\n",
    "\n",
    "</p>\n",
    "\n",
    "# Perceptrons\n",
    "\n",
    "## Freshman Research Initiative Energy Analytics CS 309\n",
    "\n",
    "#### Jesse Pisel, Assistant Professor of Practice, University of Texas at Austin\n",
    "**[Twitter](http://twitter.com/geologyjesse)** | **[GitHub](https://github.com/jessepisel)** | **[GoogleScholar](https://scholar.google.com/citations?user=Z4JzYgIAAAAJ&hl=en&oi=ao)** | **[LinkedIn](https://www.linkedin.com/in/jesse-pisel-70519430/)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use the same packages and data organization for the rest of the semester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "import seaborn as sns; sns.set()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        DEPT   AHT10   AHT20   AHT30   AHT60   AHT90   AHTCO60   AHTCO90  \\\n",
       "5466  1914.0  1.6167  3.0335  7.5475  8.5244  9.1691  117.3103  109.0619   \n",
       "5467  1913.5  1.6164  3.0324  7.5492  8.5195  9.1830  117.3782  108.8963   \n",
       "5468  1913.0  1.6163  3.0317  7.5488  8.5243  9.1852  117.3116  108.8711   \n",
       "5469  1912.5  1.6162  3.0311  7.5493  8.5248  9.1936  117.3051  108.7711   \n",
       "5470  1912.0  1.6161  3.0305  7.5496  8.5289  9.1974  117.2483  108.7263   \n",
       "\n",
       "        DPHZ    DSOZ  ...     ITT    NPOR     PEFZ    RSOZ    RXOZ    SDEV  \\\n",
       "5466 -0.4129  0.5048  ...  0.2649  0.4847  10.0000  0.0348  2.9599  1.0538   \n",
       "5467 -0.6763  0.3208  ...  0.2650  0.4760  10.0000  0.0000  1.7452  1.0770   \n",
       "5468 -0.9772  0.2371  ...  0.2651  0.4754  10.0000  0.0000  0.3407  1.0509   \n",
       "5469 -1.1748  0.2120  ...  0.2652  0.4853  10.0000  0.0000  0.2168  0.8236   \n",
       "5470 -1.1654  0.2080  ...  0.2652  0.4471   9.9845  0.0000  0.1797  0.7958   \n",
       "\n",
       "            SP    SPHI    RHOZ        TOP  \n",
       "5466    1.6250  0.7009  3.3313  MATANUSKA  \n",
       "5467   10.9375  0.6161  3.7659  MATANUSKA  \n",
       "5468   43.8125  0.5991  4.2624  MATANUSKA  \n",
       "5469   79.5000  0.6521  4.5884  MATANUSKA  \n",
       "5470  108.5000  0.6699  4.5729  MATANUSKA  \n",
       "\n",
       "[5 rows x 28 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>DEPT</th>\n      <th>AHT10</th>\n      <th>AHT20</th>\n      <th>AHT30</th>\n      <th>AHT60</th>\n      <th>AHT90</th>\n      <th>AHTCO60</th>\n      <th>AHTCO90</th>\n      <th>DPHZ</th>\n      <th>DSOZ</th>\n      <th>...</th>\n      <th>ITT</th>\n      <th>NPOR</th>\n      <th>PEFZ</th>\n      <th>RSOZ</th>\n      <th>RXOZ</th>\n      <th>SDEV</th>\n      <th>SP</th>\n      <th>SPHI</th>\n      <th>RHOZ</th>\n      <th>TOP</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>5466</th>\n      <td>1914.0</td>\n      <td>1.6167</td>\n      <td>3.0335</td>\n      <td>7.5475</td>\n      <td>8.5244</td>\n      <td>9.1691</td>\n      <td>117.3103</td>\n      <td>109.0619</td>\n      <td>-0.4129</td>\n      <td>0.5048</td>\n      <td>...</td>\n      <td>0.2649</td>\n      <td>0.4847</td>\n      <td>10.0000</td>\n      <td>0.0348</td>\n      <td>2.9599</td>\n      <td>1.0538</td>\n      <td>1.6250</td>\n      <td>0.7009</td>\n      <td>3.3313</td>\n      <td>MATANUSKA</td>\n    </tr>\n    <tr>\n      <th>5467</th>\n      <td>1913.5</td>\n      <td>1.6164</td>\n      <td>3.0324</td>\n      <td>7.5492</td>\n      <td>8.5195</td>\n      <td>9.1830</td>\n      <td>117.3782</td>\n      <td>108.8963</td>\n      <td>-0.6763</td>\n      <td>0.3208</td>\n      <td>...</td>\n      <td>0.2650</td>\n      <td>0.4760</td>\n      <td>10.0000</td>\n      <td>0.0000</td>\n      <td>1.7452</td>\n      <td>1.0770</td>\n      <td>10.9375</td>\n      <td>0.6161</td>\n      <td>3.7659</td>\n      <td>MATANUSKA</td>\n    </tr>\n    <tr>\n      <th>5468</th>\n      <td>1913.0</td>\n      <td>1.6163</td>\n      <td>3.0317</td>\n      <td>7.5488</td>\n      <td>8.5243</td>\n      <td>9.1852</td>\n      <td>117.3116</td>\n      <td>108.8711</td>\n      <td>-0.9772</td>\n      <td>0.2371</td>\n      <td>...</td>\n      <td>0.2651</td>\n      <td>0.4754</td>\n      <td>10.0000</td>\n      <td>0.0000</td>\n      <td>0.3407</td>\n      <td>1.0509</td>\n      <td>43.8125</td>\n      <td>0.5991</td>\n      <td>4.2624</td>\n      <td>MATANUSKA</td>\n    </tr>\n    <tr>\n      <th>5469</th>\n      <td>1912.5</td>\n      <td>1.6162</td>\n      <td>3.0311</td>\n      <td>7.5493</td>\n      <td>8.5248</td>\n      <td>9.1936</td>\n      <td>117.3051</td>\n      <td>108.7711</td>\n      <td>-1.1748</td>\n      <td>0.2120</td>\n      <td>...</td>\n      <td>0.2652</td>\n      <td>0.4853</td>\n      <td>10.0000</td>\n      <td>0.0000</td>\n      <td>0.2168</td>\n      <td>0.8236</td>\n      <td>79.5000</td>\n      <td>0.6521</td>\n      <td>4.5884</td>\n      <td>MATANUSKA</td>\n    </tr>\n    <tr>\n      <th>5470</th>\n      <td>1912.0</td>\n      <td>1.6161</td>\n      <td>3.0305</td>\n      <td>7.5496</td>\n      <td>8.5289</td>\n      <td>9.1974</td>\n      <td>117.2483</td>\n      <td>108.7263</td>\n      <td>-1.1654</td>\n      <td>0.2080</td>\n      <td>...</td>\n      <td>0.2652</td>\n      <td>0.4471</td>\n      <td>9.9845</td>\n      <td>0.0000</td>\n      <td>0.1797</td>\n      <td>0.7958</td>\n      <td>108.5000</td>\n      <td>0.6699</td>\n      <td>4.5729</td>\n      <td>MATANUSKA</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 28 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "data = pd.read_csv(r'well_data.csv') #read it in\n",
    "data.tail()"
   ]
  },
  {
   "source": [
    "We want to balance our classes so that the classifier doesn't learn to majority vote for the predictions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = data.groupby('TOP')\n",
    "balanced = groups.apply(lambda x: x.sample(groups.size().min()).reset_index(drop=True))\n",
    "balanced = balanced.reset_index(level=1, drop=True)\n",
    "data = balanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember we want to label encode our formation tops that we want to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing #for label encoding\n",
    "#label encode our formation data\n",
    "le = preprocessing.LabelEncoder()\n",
    "top_names = data.TOP\n",
    "le.fit(data.TOP)\n",
    "tops = le.transform(data.TOP)\n",
    "tops[tops == 0] = -1 #remember perceptrons are a -1 or +1 classification scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('TOP', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we also need to split our data into train and test subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, tops, test_size=0.2, random_state=86)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's define the prediction part of our perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, weights):\n",
    "    n_samples = X.shape[0]\n",
    "    # Add column of 1 on the feature tensor for the bias term\n",
    "    X = np.concatenate([X, np.ones((n_samples, 1))], axis=1)\n",
    "    y = np.matmul(X, weights)\n",
    "    y = np.vectorize(lambda val: 1 if val > 0 else -1)(y)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's also define a function that we will use to fit the perceptron to our data. the number of `epochs` is the number of times we want to run through our training dataset. One time through the entire dataset is one epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(features, target, epochs, learning_rate):\n",
    "    n_samples, n_features = features.shape\n",
    "    lr = learning_rate\n",
    "    weights = np.zeros((n_features+1))\n",
    "    # this adds the bias term as an input vector on the feature tensor\n",
    "    features = np.concatenate([features, np.ones((n_samples, 1))], axis=1)\n",
    "    for e in range(epochs):\n",
    "        for j in range(n_samples):\n",
    "            # add your code in so that the function loops though every sample\n",
    "            # calculates the error, and then updates the weights\n",
    "            # error = y - y_hat\n",
    "            # weights = previous weights + learning rate * error * features\n",
    "            error = target[j]-np.dot(weights, features[j,:])\n",
    "            if error !=0:\n",
    "                weights+=lr*error*features[j,:]\n",
    "        if e % (epochs / 10) == 0:\n",
    "            y_hat = predict(X_test, weights)\n",
    "            print(f\"Epoch: {e:^5}{'=====':^5} Accuracy: {accuracy_score(y_test, y_hat):.2f}\")\n",
    "            print(\"__________\")\n",
    "    print(\"Finished training!\")\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly we need to declare how many epochs to train for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch:   0  ===== Accuracy: 0.49\n",
      "__________\n",
      "Epoch:  10  ===== Accuracy: 0.55\n",
      "__________\n",
      "Epoch:  20  ===== Accuracy: 0.75\n",
      "__________\n",
      "Epoch:  30  ===== Accuracy: 0.87\n",
      "__________\n",
      "Epoch:  40  ===== Accuracy: 0.91\n",
      "__________\n",
      "Epoch:  50  ===== Accuracy: 0.93\n",
      "__________\n",
      "Epoch:  60  ===== Accuracy: 0.94\n",
      "__________\n",
      "Epoch:  70  ===== Accuracy: 0.96\n",
      "__________\n",
      "Epoch:  80  ===== Accuracy: 0.96\n",
      "__________\n",
      "Epoch:  90  ===== Accuracy: 0.96\n",
      "__________\n",
      "Finished training!\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "weight = fit(X_train, y_train, epochs, 0.000000001) #0.00000001\n",
    "y_hat = predict(X_test, weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's check and see how close our perceptron is in accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The perceptrons accuracy is 0.96\n"
     ]
    }
   ],
   "source": [
    "print(f'The perceptrons accuracy is {round(accuracy_score(y_test, y_hat),2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[142,  11],\n",
       "       [  0, 145]], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_hat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9664429530201343"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "perc = Perceptron()\n",
    "perc.fit(X_train, y_train)\n",
    "perc.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[145,   8],\n",
       "       [  2, 143]], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "confusion_matrix(y_test, perc.predict(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}